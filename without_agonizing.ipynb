{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robert Swain's jury\n",
    "\n",
    "Here is some codey stuff that we'll need later.  Please ignore the code in this cell, but don't forget to run it.\n",
    "\n",
    "If you get 'not defined' errors in the code cells, please navigate up here, and run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff for working with arrays of numbers.\n",
    "from numpy import count_nonzero, arange, zeros, array, mean, append, repeat\n",
    "# Random numbers and shuffling.\n",
    "from numpy.random import randint, shuffle\n",
    "# Some statistical tests to compare with the agonizing way.\n",
    "from scipy.stats import ttest_ind as ttest, chi2_contingency as chi2, binom\n",
    "# Utility for making tables.\n",
    "from pandas import crosstab\n",
    "# Doing histogram plots in the browser.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how to make a random number from 1 through 4 (1 up to, but not including, 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randint(1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store the result with a *variable*.  The variable gives a label to the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = randint(1, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask Python to compare the number to 1. Notice the `==`.  This means \"give me True if the number on the left is equal to the number on the right, and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make 12 random numbers from 1 through 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jurors = randint(1, 5, 12)\n",
    "jurors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `==` to check whether *each* of these numbers is equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jurors == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`count_nonzero` counts how many True values there are.  Therefore, in our case,\n",
    "it gives the number of values in `jurors` that are equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nonzero(jurors == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this a few times, to get an idea of the numbers that come up often.  Use Ctrl-Enter a few times to run this cell several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jurors = randint(1, 5, 12)\n",
    "result = count_nonzero(jurors == 1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fancy bit.  We repeat the process above 10000 times.  We use the new variable `results` to store the count we got, each time we make a new jury."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = zeros(10000)\n",
    "for i in arange(10000):\n",
    "    jurors = randint(1, 5, 12)\n",
    "    result = count_nonzero(jurors == 1)\n",
    "    results[i] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first 10 of the 10000 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a histogram of all 10000 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think - is 0 common, uncommon, or rare?\n",
    "\n",
    "Here are the number of times we saw 0 in our 10000 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_zeros = count_nonzero(results == 0)\n",
    "n_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the proportion of zeros.  Therefore, it is the probability that any one trial will give us 0 black jurors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_zeros = n_zeros / 10000\n",
    "p_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is called *simulation*.  It is a very powerful and general way of solving many statistical problems.  There is also a less general mathematical formula for solving some of these kinds of problems, which you might have heard of, called the *binomial* distribution.   Most people who have heard of it, don't have a good understanding of *why* it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability of getting 0 from 12 trials where each has a probability of 0.25 of # giving a \"success\" - in our case - a black juror.\n",
    "binom(12, 0.25).cdf(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mosquitoes\n",
    "\n",
    "See <https://github.com/matthew-brett/datasets/tree/master/mosquito_beer>.\n",
    "\n",
    "Here are the numbers of mosquitoes that flew out of their box for each beer drinker.  There were 25 beer drinkers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer = array([14, 33, 27, 11, 12, 27, 26, 25, 27, 27, 22, 36, 37,  3, 23,  7, 25,\n",
    "              17, 36, 31, 30, 22, 20, 29, 23])\n",
    "beer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the corresponding numbers for the water drinkers.  There were 18 water drinkers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water = array([33, 23, 23, 13, 24,  8,  4, 21, 24, 21, 26, 27, 22, 21, 25, 20,  7,\n",
    "        3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of the mosquito numbers across the 25 beer drinkers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(beer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of the mosquito numbers across the 18 water drinkers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(water)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the means is a measure of how different the numbers were between the beer and the water drinkers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_diff = mean(beer) - mean(water)\n",
    "actual_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put these 25 + 18 values into one virtual bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = append(beer, water)\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, at the moment, the first 25 values are the beer drinker numbers, and the last 18 are from the water drinkers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(bucket[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(bucket[25:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shuffle the values (like shaking the bucket).  The values are in a random order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(bucket)\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 25 values are a mix of the beer and water counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(bucket[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 18 are also a mixture of beer and water counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(bucket[25:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we subtract the difference between these means, we get a fake difference; the kind of difference we would see if the beer and water counts are really just the same kind of thing, and we had taken a random sample of 25, and 18, from these same-kind-of-thing numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_diff = mean(bucket[:25]) - mean(bucket[25:])\n",
    "fake_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the same thing again, all in one shot.  Run a few times with Ctrl-Enter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(bucket)\n",
    "fake_diff = mean(bucket[:25]) - mean(bucket[25:])\n",
    "fake_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat this process above 10000 times to get 10000 fake difference estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = zeros(10000)\n",
    "for i in arange(10000):\n",
    "    shuffle(bucket)\n",
    "    fake_diff = mean(bucket[:25]) - mean(bucket[25:])\n",
    "    results[i] = fake_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the histogram of these fake differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A value greater than, or equal to our actual value is somewhat uncommon, in\n",
    "this distribution, but not rare.  It happens about 6% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gte_actual = count_nonzero(results >= actual_diff)\n",
    "n_gte_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_gte_actual = n_gte_actual / 10000\n",
    "p_gte_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way that you may have been taught to solve this problem, it the t-test.  Very few people understand the t-test in any depth.  As well as being hard to understand, it is not as useful as the *permutation* test that you did above, because it relies on assumptions like sample sizes greater than about 30, and normal distribution for the values; assumptions we don't need for the permutation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_res = ttest(beer, water)\n",
    "ttest_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the p value for the t-test above is 2-tailed.  The one-tailed value, comparable to the permutation test above, is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_res.pvalue / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescuers and democracy\n",
    "\n",
    "Here are some counts from Oliner and Oliner 1988, table 6.8. See:\n",
    "<https://github.com/matthew-brett/datasets/tree/master/oliner1988>.\n",
    "\n",
    "| .         |Democratic|Other| Total |\n",
    "|-----------|----------|-----|-------|\n",
    "| Bystander |         1|    6|     7 |\n",
    "| Rescuer   |        32|    8|    40 |\n",
    "| Total     |        33|   14|    47 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build up the individuals these counts refer to by making two sets of 47\n",
    "labels.  The first set gives labels for the people, \"Rescuer\" or \"Bystander\".\n",
    "The second set gives labels for the parties these people belonged to:\n",
    "\"Democratic\" or \"Other\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescue_or_not = repeat(['Rescuer', 'Bystander'], [40, 7])\n",
    "democratic_or_other = repeat(['Democratic', 'Other', 'Democratic', 'Other'], [32, 8, 1, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate a cross-tabulation for these 47 pairs, to get counts for rescuers and bystanders for democratic and other parties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = crosstab(rescue_or_not, democratic_or_other)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we get the counts for pairs where the first label says\n",
    "\"Bystander\" and the second label says \"Democratic\".  It's the top-left value of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_count = table.loc['Bystander', 'Democratic']\n",
    "actual_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can shuffle both sets of labels, so the pairs are now random, but we still have the same numbers of Rescuers, Bystanders, Democratic and Other.  Then we make a new table for this random pairing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(rescue_or_not)\n",
    "shuffle(democratic_or_other)\n",
    "fake_table = crosstab(rescue_or_not, democratic_or_other)\n",
    "fake_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we look at the top-left value in this fake table, for Bystanders who now appear to be Democratic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_count = fake_table.loc['Bystander', 'Democratic']\n",
    "fake_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this 1000 times (10000 gets a bit slow in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = zeros(1000)\n",
    "for i in arange(1000):\n",
    "    shuffle(rescue_or_not)\n",
    "    shuffle(democratic_or_other)\n",
    "    fake_table = crosstab(rescue_or_not, democratic_or_other)\n",
    "    fake_count = fake_table.loc['Bystander', 'Democratic']\n",
    "    results[i] = fake_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion of results in the fake pairings that had 1 or 0 in the top-left corner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lte_actual = count_nonzero(results <= actual_count)\n",
    "n_lte_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lte_actual = n_lte_actual / 1000\n",
    "p_lte_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do this kind of test with something called Chi-squared.  It's rather difficult to explain, but gives a similar result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2, p_value, df, expected = chi2(table)\n",
    "p_value"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
